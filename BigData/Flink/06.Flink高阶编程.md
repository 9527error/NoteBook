**所谓的高阶部分内容，其实就是Flink与其他计算框架不相同且占优势的地方，比如Window和Exactly-Once，接下来我们就对这些内容进行详细的学习。**



### window

#### 窗口概述

流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，**而Window窗口是一种切割无限数据为有限块进行处理的手段。**

![1569211243959](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211243959.png)



#### 时间窗口

timewindow：按照时间生成Window，根据窗口实现原理可以分成三类



- 滚动窗口(Tumbling Window)：

**将数据依据固定的窗口长度对数据进行切片。**滚动窗口分配器将每个元素分配到一个指定窗口大小的窗口中，滚动窗口有一个固定的大小，**并且不会出现重叠**。

适用场景：适合做BI统计等（做每个时间段的聚合计算）



![1569211246514](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211246514.png)



```java
.timeWindow(Time.seconds(15))
```



- 滑动窗口(Sliding Window)：

滑动窗口是固定窗口的更广义的一种形式，**滑动窗口由固定的窗口长度和滑动间隔组成**。滑动窗口分配器将元素分配到固定长度的窗口中，与滚动窗口类似，窗口的大小由窗口大小参数来配置，另一个窗口滑动参数控制滑动窗口开始的频率。因此，滑动窗口如果滑动参数小于窗口大小的话，**窗口是可以重叠的**，在这种情况下元素会被分配到多个窗口中。

适用场景：对最近一个时间段内的统计, 比如求最近1小时内每5分钟的水位变化

![1569211221311](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211221311.png)

```
.timeWindow(Time.seconds(15),Time.seconds(5))
```



- 会话窗口(Session Window)；

由一系列事件组合一个指定时间长度的timeout间隙组成，类似于web应用的session,也就是一段时间没有接收到新数据就会生成新的窗口。

![1569211228282](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211228282.png)

```
.window(EventTimeSessionWindows.withGap(Time.minutes(10)))
```



计数窗口

countwindow：按照指定的数据条数生成一个Window，与时间无关。根据窗口实现原理可以分成两类:



- 滚动窗口

默认的CountWindow是一个滚动窗口，只需要指定窗口大小即可，当元素数量达到窗	口大小时，就会触发窗口的执行

```
.countWindow(5)
```

- 滑动窗口

滑动窗口和滚动窗口的函数名是完全一致的，只是在传参数时需要传入两个参数，一个是window_size，一个是sliding_size。下面代码中的sliding_size设置为了2，也就是说，每收到两个相同key的数据就计算一次，每一次计算的window范围是3个元素。

```java
val dataDS = env.socketTextStream("hadoop02", 9999)

val mapDS = dataDS.map(data=>{
    val datas = data.split(",")
    (datas(0),datas(2).toInt)
})

val reduceDS = mapDS.keyBy(_._1)
    .countWindow(3,2).reduce(
    (t1, t2) => {
        (t1._1, t1._2 + t2._2)
    }
)

reduceDS.print()
```



#### 窗口API



- 增量聚合函数（incremental aggregation functions）

**每条数据到来就进行计算**，保持一个简单的状态。（来一条处理一条，但是不输出，到窗口临界位置才输出）

典型的增量聚合函数有ReduceFunction, AggregateFunction。



- [ ] ReduceFunction

  ```
  val dataDS: DataStream[String] =
   env.socketTextStream("hadoop02", 9999)
  
  val mapDS = dataDS.map(data=>{
      val datas = data.split(",")
      (datas(0),datas(2).toInt)
  })
  
  val reduceDS: DataStream[(String, Int)] = mapDS.keyBy(_._1)
      .timeWindow(Time.seconds(3)).reduce(
          new ReduceFunction[(String, Int)] {
              override def reduce(t: (String, Int), t1: (String, Int)): (String, Int) = {
                  (t._1, t._2 + t1._2)
              }
          }
      )
  reduceDS.print()
  ```

- [ ] AggregateFunction

  ```
  val dataDS: DataStream[String] =
   env.socketTextStream("hadoop02", 9999)
  
  val mapDS = dataDS.map(data=>{
      val datas = data.split(",")
      (datas(0),datas(2).toInt)
  })
  
  val aggregateDS: DataStream[(String, Int)] = mapDS.keyBy(_._1)
      .countWindow(3).aggregate(
          // TODO 此处聚合函数类似于Spark中的累加器
          new AggregateFunction[(String, Int), (Int, Int), (String, Int)] {
              override def createAccumulator(): (Int, Int) = {
                  (0,0)
              }
  
              override def add(in: (String, Int), acc: (Int, Int)): (Int, Int) = {
                  (in._2 + acc._1, acc._2 + 1)
              }
  
              override def getResult(acc: (Int, Int)): (String, Int) = {
                  ("sensor", (acc._1 / acc._2))
              }
  
              override def merge(acc: (Int, Int), acc1: (Int, Int)): (Int, Int) = {
                  (acc._1 + acc1._1, acc._2 + acc1._2)
              }
          }
      )
  
  aggregateDS.print()
  ```



- 全窗口函数(full window functions)

  **先把窗口所有数据收集起来，等到计算的时候会遍历所有数据。**

  典型的全窗口函数：ProcessWindowFunction，WindowFunction。

  ```
  val dataDS: DataStream[String] =
   env.socketTextStream("hadoop02", 9999)
  
  val mapDS = dataDS.map(data=>{
      val datas = data.split(",")
      (datas(0),datas(2).toInt)
  })
  
  val processDS: DataStream[String] = mapDS.keyBy(_._1)
      .countWindow(3)
      .process(new ProcessWindowFunction[(String, Int), String, String, GlobalWindow] {
          override def process(key: String, context: Context, elements: Iterable[(String, Int)], out: Collector[String]): Unit = {
              //println(elements.mkString(","))
              out.collect(elements.mkString(","))
          }
      })
  processDS.print()
  ```


- 其他API
  - `.trigger()` ——触发器:定义window 什么时候关闭，触发计算并输出结果
  - `.evitor()` ——移除器:定义移除某些数据的逻辑
  - `.allowedLateness()` ——允许处理迟到的数据
  - `.sideOutputLateData()` ——将迟到的数据放入侧输出流
  - `.getSideOutput()` ——获取侧输出流



### 时间语义和waterMark



#### 时间语义

![1569211228039](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211228039.png)

- Event Time：是事件创建的时间。**它通常由事件中的时间戳(日志数据里的时间)描述**，例如采集的日志		数据中，每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问事件	时间戳。
- Ingestion Time：**数据进入Flink的时间；**
- Processing Time：执行操作算子的**本地系统时间**，与机器相关；



Flink是一个事件驱动的计算框架，就意味着每来一条数据，才应该触发Flink中的计算。

**默认情况下，Flink框架中处理的时间语义为ProcessingTime**

使用eventTime，需要引入eventTime的时间属性

```java
import org.apache.flink.streaming.api.TimeCharacteristic

val env: StreamExecutionEnvironment = 
StreamExecutionEnvironment.getExecutionEnvironment
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
```



#### waterMark

```
Flink流计算编程--watermark（水位线）简介:
https://blog.csdn.net/lmalds/article/details/52704170
```



- 什么是waterMark

  **针对数据乱序的产生，我们不能无限期的等下去，必须要有一个机制来保证一个特定时间后，必须触发window来去计算，这个机制就是watermark**



  **watermark可以理解为把原本的窗口标准稍微放宽了一点。（比如原本5s，设置延迟时间=2s，那么实际等到7s的数据到达时，才认为是[0,5）的桶需要关闭了）**



  ![1569211221528](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211221528.png)

  - [ ] 当Flink以**Event Time模式**处理数据流时，它会根据**数据里的时间戳**来处理基于时间的算子。

  （比如5s一个窗口，那么理想情况下，遇到时间戳是5s的数据时，就认为[0,5s)时间段的桶bucket就可以关闭了。）

  - [ ] 实际由于网络、分布式传输处理等原因，会导致乱序数据的产生

  - [ ] 乱序数据会导致窗口计算不准确



- 怎样避免乱序数据带来的计算不正确？
- 遇到一个时间戳达到了窗口关闭时间，不应该立即触发窗口计算，而是等待一段时间，等迟到的数据来了再关闭窗口

1. Watermark是一种衡量Event Time进展的机制，可以设定延迟触发

2. Watermark是用于处理乱序事件的，而正确的处理乱序事件，通常用Watermark机制结合window来实现

3. 数据流中的Watermark用于表示”timestamp小于Watermark的数据，都已经到达了“，因此，window的执行也是由Watermark触发的。

4. Watermark可以理解成一个延迟触发机制，我们可以设置Watermark的延时时长t，每次系统会校验已经到达的数据中最大的maxEventTime，然后认定eventTime小于maxEventTime - t的所有数据都已经到达，**如果有窗口的停止时间等于maxEventTime – t，那么这个窗口被触发执行。**

   ```
   Watermark = maxEventTime-延迟时间t
   ```

5. watermark 用来让程序自己平衡延迟和结果正确性





   当Flink接收到数据时，会按照一定的规则去生成Watermark，这条Watermark就等于当前所有到达数据中的maxEventTime-延迟时长，也就是说，**Watermark是基于数据携带的时间戳生成的**，一旦Watermark比当前未触发的窗口的停止时间要晚，那么就会触发相应窗口的执行。



​    **由于event time是由数据携带的，因此，如果运行过程中无法获取新的数据，那么没有被触发的窗口将永远都不被触发**。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200526204111817.png)





- **waterMark的特点**

  - watermark 是一条特殊的数据记录
  - **watermark 必须单调递增**，以确保任务的事件时间时钟在向前推进，而不是在后退
  - watermark 与数据的时间戳相关



  根据不同的数据处理场景watermark会有不同的生成方式：

  1) 有序数据：DataStream.assignAscendingTimestamps

  2) 乱序数据：DataStream.assignTimestampsAndWatermarks

  乱序数据中的watermark处理又分两大类：

  Ø AssignerWithPeriodicWatermarks

  Ø AssignerWithPunctuatedWatermarks



  - [ ] **怎么知道是乱序？怎么知道是迟到的数据？**

  基于事件时间，才知道是否乱序

  - [ ] **·已经知道数据有乱序，做一个窗口的操作，用EventTime来触发窗口的关闭和计算，合适么？**

  不合适，因为数据有乱序，不能用ET来触发窗口的关闭和计算，需要其他东西来衡量时间的进展

  - [ ] **·Watermark**

  => 表示时间的进展

  => 用来触发窗口的关闭和计算

  => 解决乱序的问题

  => 是单调递增的

  => 是一个时间戳

  =>表示在它之前的数据，都已经到齐了

  - [ ]  **Watermark设定了等待时间，如果过了等待时间，数据还没到齐，怎么办**

  窗口设置允许迟到 =>allowedlateness

  - [ ] **如果窗口设置了延迟时间，但是到了真正的关窗时间，这个窗口的数据还没到，怎么办**

    放到侧输出流，存起来



  - Flink对于迟到数据有三层保障

    ，先来后到的保障顺序是：

    - WaterMark => 约等于放宽窗口标准
    - allowedLateness => 允许迟到（ProcessingTime超时，但是EventTime没超时）
    - sideOutputLateData => 超过迟到时间，另外捕获，之后可以自己批处理合并先前的数据





  ### ProcessFunction API

DataStream API提供了一系列的Low-Level转换算子。可以访问时间戳、watermark以及注册定时事件。

**所有的Process Function都继承自RichFunction接口,所以都有open()、close()和getRuntimeContext()等方法。**



  ##### KeyedProcessFunction

- l processElement(v: IN, ctx: Context, out: Collector[OUT]), 流中的每一个元素都会调用这个方法，调用结果将会放在Collector数据类型中输出。Context可以访问元素的时间戳，元素的key，以及TimerService时间服务。Context还可以将结果输出到别的流(side outputs)。

- onTimer(timestamp: Long, ctx: OnTimerContext, out: Collector[OUT])是一个回调函数。当之前注册的定时器触发时调用。参数timestamp为定时器所设定的触发的时间戳。Collector为输出结果的集合。OnTimerContext和processElement的Context参数一样，提供了上下文的一些信息，例如定时器触发的时间信息(事件时间或者处理时间)。

  ```
  val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
  env.setParallelism(1)
  
  val dataDS: DataStream[String] = env.readTextFile("input/data1.txt")
  
  val mapDS: DataStream[(String, Long, Int)] = dataDS.map(data => {
      val datas = data.split(",")
      (datas(0), datas(1).toLong, datas(2).toInt)
  })
  
  mapDS.keyBy(0)
          .process(
              new KeyedProcessFunction[Tuple,(String, Long, Int), String]{
                  override def onTimer(timestamp: Long, ctx: KeyedProcessFunction[Tuple, (String, Long, Int), String]#OnTimerContext, out: Collector[String]): Unit = super.onTimer(timestamp, ctx, out)
                  
  override def processElement(value: (String, Long, Int), ctx: KeyedProcessFunction[Tuple, (String, Long, Int), String]#Context, out: Collector[String]): Unit = {
                      println(ctx.getCurrentKey)
                      out.collect(value.toString())
                  }
              }
          ).print("keyprocess:")
  ```


##### TimerService和定时器(Timer)

Context和OnTimerContext所持有的TimerService对象拥有以下方法:

- currentProcessingTime(): Long 返回当前处理时间

- currentWatermark(): Long 返回当前watermark的时间戳

- registerProcessingTimeTimer(timestamp: Long): Unit 会注册当前key的processing time的定时器。当processing time到达定时时间时，触发timer。

- registerEventTimeTimer(timestamp: Long): Unit 会注册当前key的event time 定时器。当水位线大于等于定时器注册的时间时，触发定时器执行回调函数。

- deleteProcessingTimeTimer(timestamp: Long): Unit 删除之前注册处理时间定时器。如果没有这个时间戳的定时器，则不执行。

- deleteEventTimeTimer(timestamp: Long): Unit 删除之前注册的事件时间定时器，如果没有此时间戳的定时器，则不执行。

- 当定时器timer触发时，会执行回调函数onTimer()。注意定时器timer只能在keyed streams上面使用。



需求：监控水位传感器的水位值，如果水位值在五分钟之内(processing time)连续上升，则报警。

```
import bean.WaterSensor;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.streaming.api.TimeCharacteristic;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.streaming.api.watermark.Watermark;
import org.apache.flink.util.Collector;

import javax.annotation.Nullable;
import java.sql.Timestamp;


//连续5s 水位上升，进行告警
public class Flink15_ProcessFunction_TimePractice {
    public static void main(String[] args) throws Exception {
        //0.执行环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        env.setParallelism(1);

        //TODO 指定时间语义
        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

        SingleOutputStreamOperator<WaterSensor> sensorDS = env.socketTextStream("localhost", 9999)
                .map(new MapFunction<String, WaterSensor>() {
                    @Override
                    public WaterSensor map(String value) throws Exception {
                        String[] datas = value.split(",");

                        return new WaterSensor(datas[0], Long.valueOf(datas[1]), Integer.valueOf(datas[2]));
                    }
                })
                //TODO 如何从事件从抽取出事件时间  时间单位是 ms

                .assignTimestampsAndWatermarks(
//                        new AscendingTimestampExtractor<WaterSensor>() {
//                            @Override
//                            public long extractAscendingTimestamp(WaterSensor element) {
//                                return element.getTs() * 1000L;
//                            }
//                        }
                        new AssignerWithPunctuatedWatermarks<WaterSensor>() {

                            private Long maxTS = Long.MIN_VALUE;
                            @Nullable
                            @Override
                            public Watermark checkAndGetNextWatermark(WaterSensor lastElement, long extractedTimestamp) {
                                maxTS = Math.max(maxTS,extractedTimestamp);

                                return new Watermark(maxTS);
                            }

                            @Override
                            public long extractTimestamp(WaterSensor element, long previousElementTimestamp) {
                                return element.getTs() * 1000L;
                            }
                        }
                );
        SingleOutputStreamOperator<String> processDS = sensorDS.keyBy(data -> data.getId())
                .process(
                        new KeyedProcessFunction<String, WaterSensor, String>() {
                            //定义一个变量，保存上一次的水位值
                            private  Integer LastVC = 0;
                            private  Long triggerTS = 0L;

                            //来一条数据处理一条

                            @Override
                            public void processElement(WaterSensor value, Context ctx, Collector<String> out) throws Exception {
                                if (value.getVc() > LastVC){
                                    //水位上升
                                    //第一条数据来的时候，注册定时器
                                    if(triggerTS == 0){
                                        ctx.timerService().registerProcessingTimeTimer(value.getTs() * 1000L + 5000L);
                                        triggerTS = value.getTs() * 1000L + 5000L;
                                    }
                                }else {
                                    //水位下降
                                    //删除定时器
                                    ctx.timerService().deleteEventTimeTimer(triggerTS);
                                    //把保存的时间清空
                                    triggerTS = 0L;
                                }

                                //不管上升还是下降，都要保存水位值，供下条数据使用，进行比较
                            }
                            //定时器触发
                            @Override
                            public void onTimer(long timestamp, OnTimerContext ctx, Collector<String> out) throws Exception {
                                out.collect(ctx.getCurrentKey() + " 在" + timestamp + "监测到水位连续5s上升");

                                //将保存的注册时间清空
                                triggerTS = 0L;
                            }
                        }
                );
        processDS.print();
        env.execute();
    }
}
```



##### 侧输出流(SideOutput)

process function的side outputs功能可以产生多条流，并且这些流的数据类型可以不一样。**一个side output可以定义为OutputTag[X]对象，X是输出流的数据类型。process function可以通过Context对象发送一个事件到一个或者多个side outputs。**



```
import bean.WaterSensor;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.streaming.api.TimeCharacteristic;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.streaming.api.watermark.Watermark;
import org.apache.flink.util.Collector;
import org.apache.flink.util.OutputTag;

import javax.annotation.Nullable;


//水位高于阈值 通过侧输出流告警
public class Flink16_ProcessFunction_SideOutPut {
    public static void main(String[] args) throws Exception {
        //0.执行环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        env.setParallelism(1);

        //TODO 指定时间语义
        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

        SingleOutputStreamOperator<WaterSensor> sensorDS = env.socketTextStream("localhost", 9999)
                .map(new MapFunction<String, WaterSensor>() {
                    @Override
                    public WaterSensor map(String value) throws Exception {
                        String[] datas = value.split(",");

                        return new WaterSensor(datas[0], Long.valueOf(datas[1]), Integer.valueOf(datas[2]));
                    }
                })
                //TODO 如何从事件从抽取出事件时间  时间单位是 ms

                .assignTimestampsAndWatermarks(
//                        new AscendingTimestampExtractor<WaterSensor>() {
//                            @Override
//                            public long extractAscendingTimestamp(WaterSensor element) {
//                                return element.getTs() * 1000L;
//                            }
//                        }
                        new AssignerWithPunctuatedWatermarks<WaterSensor>() {

                            private Long maxTS = Long.MIN_VALUE;
                            @Nullable
                            @Override
                            public Watermark checkAndGetNextWatermark(WaterSensor lastElement, long extractedTimestamp) {
                                maxTS = Math.max(maxTS,extractedTimestamp);

                                return new Watermark(maxTS);
                            }

                            @Override
                            public long extractTimestamp(WaterSensor element, long previousElementTimestamp) {
                                return element.getTs() * 1000L;
                            }
                        }
                );
        //TODO 使用侧输出流
        //1.定义一个outputTag，给定一个名称
        //2.使用ctx.output(outputTag对象，放入侧输出流的数据)
        //3.获取侧输出流 =>DataStream.getSideOutput(output对象)
        OutputTag<String> outputTag = new OutputTag<String>("vc alarm"){};

        SingleOutputStreamOperator<WaterSensor> processDS = sensorDS.
                keyBy(data -> data.getId())
                .process(
                        new KeyedProcessFunction<String, WaterSensor, WaterSensor>() {


                            @Override
                            public void processElement(WaterSensor value, Context ctx, Collector<WaterSensor> out) throws Exception {
                                //水位高于阈值 侧输出流告警
                                if (value.getVc() > 5){
                                    ctx.output(outputTag,"水位超过阈值5！！！");

                                }
                                out.collect(value);
                            }
                        }
                );
        processDS.print();
        processDS.getSideOutput(outputTag).print("alarm");
        env.execute();
    }
}
```



##### CoProcessFunction

对于两条输入流，DataStream API提供了CoProcessFunction这样的low-level操作。CoProcessFunction提供了操作每一个输入流的方法: processElement1()和processElement2()。

类似于ProcessFunction，这两种方法都通过Context对象来调用。这个Context对象可以访问事件数据，定时器时间戳，TimerService，以及side outputs。CoProcessFunction也提供了onTimer()回调函数。

```
val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

val dataDS: DataStream[String] = env.readTextFile("input/data.txt")
val splitDS: SplitStream[WaterSensor] = dataDS.map(
    s => {
        val datas = s.split(",")
        WaterSensor(datas(0), datas(1).toLong, datas(2).toInt)
    }
).split(
    sensor => {
        if (sensor.vc >= 40) {
            Seq("alarm")
        } else if (sensor.vc >= 30) {
            Seq("warn")
        } else {
            Seq("normal")
        }
    }
)

val alarmDS: DataStream[WaterSensor] = splitDS.select("alarm")
val warnDS: DataStream[WaterSensor] = splitDS.select("warn")
val normalDS: DataStream[WaterSensor] = splitDS.select("normal")

val connectDS: ConnectedStreams[WaterSensor, WaterSensor] = alarmDS.connect(warnDS)

connectDS.process(new CoProcessFunction[WaterSensor, WaterSensor, WaterSensor] {
    override def processElement1(value: WaterSensor, ctx: CoProcessFunction[WaterSensor, WaterSensor, WaterSensor]#Context, out: Collector[WaterSensor]): Unit = {
        out.collect(value)
    }

    override def processElement2(value: WaterSensor, ctx: CoProcessFunction[WaterSensor, WaterSensor, WaterSensor]#Context, out: Collector[WaterSensor]): Unit = {
        out.collect(value)
    }
})

env.execute()
```





### 状态管理

```

```



**状态的概述**

![1569211239846](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211239846.png)



- 由一个任务维护，并且用来计算某个结果的所有数据，都属于这个任务的状态
- 可以认为任务状态就是一个本地变量，可以被任务的业务逻辑访问
- **Flink 会进行状态管理，包括状态一致性、故障处理以及高效存储和访问，以便于开发人员可以专注于应用程序的逻辑
- **在Flink中，状态始终与特定算子相关联**
- 为了使运行时的Flink了解算子的状态，算子需要预先注册其状态

**总的来说，有两种类型的状态：**

- 算子状态（Operator State）
  - 算子状态的作用范围限定为**算子任务**（也就是不能跨任务访问）
- 键控状态（Keyed State）
  - 根据输入数据流中定义的键（key）来维护和访问



##### 算子状态(Operator State)

![1569211204681](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211204681.png)



算子状态的作用范围限定为算子任务。这意味着由同一并行任务所处理的所有数据都可以访问到相同的状态，状态对于同一任务而言是共享的。**算子状态不能由相同或不同算子的另一个任务访问。**

**算子状态数据结构**：

- [ ] 列表状态（List state）

将状态表示为一组数据的列表。

- [ ] 联合列表状态（Union list state）

也将状态表示为数据的列表。它与常规列表状态的区别在于，在发生故障时，或者	从保存点（savepoint）启动应用程序时如何恢复。

- [ ]  广播状态（Broadcast state）

如果一个算子有多项任务，而它的每项任务状态又都相同，那么这种特殊情况最适合应用广播状态



##### 键控状态(keyed state)

![1569211225489](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211225489.png)



- 键控状态是根据输入数据流中定义的键（key）来维护和访问的。

- **Flink 为每个key维护一个状态实例，并将具有相同键的所有数据，都分区到同一个算子任务中，这个任务会维护和处理这个key对应的状态。**

- **当任务处理一条数据时，他会自动将状态的访问范围限定为当前数据的key**。


**键控状态数据结构：**

- 值状态(value state)
  - 将状态表示为单个的值
- 列表状态(List state)
  - 将状态表示为一组数据的列表
- 映射状态(Map state)
  - 将状态表示为一组key-value对
- **聚合状态(Reducing state & Aggregating State)**
  - 将状态表示为一个用于聚合操作的列表



##### 状态后端(State Backends)

- 每传入一条数据，有状态的算子任务都会读取和更新状态。
- 由于有效的状态访问对于处理数据的低延迟至关重要，因此每个并行任务都会在本地维护其状态，以确保快速的状态访问。
- 状态的存储、访问以及维护，由一个可插入的组件决定，这个组件就叫做**状态后端( state backend)**
- **状态后端主要负责两件事：本地状态管理，以及将检查点(checkPoint)状态写入远程存储**





**状态后端分类：**

-  **MemoryStateBackend**

内存级的状态后端，会将键控状态作为内存中的对象进行管理，将它们存储在TaskManager的JVM堆上；而将checkpoint存储在JobManager的内存中。

何时使用MemoryStateBackend？

**建议使用MemoryStateBackend进行本地开发或调试，因为它的状态有限**

MemoryStateBackend最适合具有小状态大小的用例和有状态流处理应用程序，例如仅包含一次记录功能（Map，FlatMap或Filter）的作业或使用Kafka[consumer.](https://links.jianshu.com/go?to=http://www.aboutyun.com/forum.php?mod=viewthread&tid=25592)。



- **FsStateBackend**

将checkpoint存到远程的持久化文件系统（FileSystem）上。而对于本地状态，跟MemoryStateBackend一样，也会存在TaskManager的JVM堆上。

何时使用FsStateBackend？

**FsStateBackend最适合处理大状态，长窗口或大键/值状态的Flink有状态流处理作业**

**FsStateBackend最适合每个高可用性设置**



- **RocksDBStateBackend**

将所有状态序列化后，存入本地的RocksDB中存储。

注意：RocksDB的支持并不直接包含在flink中，需要引入依赖：

```
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-statebackend-rocksdb_2.11</artifactId>
    <version>1.10.0</version>
</dependency>
```

何时使用RocksDBStateBackend？

**RocksDBStateBackend最适合处理大状态，长窗口或大键/值状态的Flink有状态流处理作业**

**RocksDBStateBackend最适合每个高可用性设置**

**RocksDBStateBackend是目前唯一可用于支持有状态流处理应用程序的增量检查点的状态后端**



##### 状态一致姓



**一致性级别：**

在流处理中，一致性可以分为3个级别：

- **at-most-once**: 这其实是**没有正确性保障的委婉说法**——故障发生之后，计数结果可能丢失。同样的还有udp。

- **at-least-once**: 这表示**计数结果可能大于正确值，但绝不会小于正确值**。也就是说,计数程序在发生故障后可能多算，但是绝不会少算。

- **exactly-once**: 这指的是系统保证**在发生故障后得到的计数结果与正确值一致。**

曾经，at-least-once非常流行。第一代流处理器(如Storm和Samza)刚问世时只保证at-least-once，原因有二。

- 保证exactly-once的系统实现起来更复杂。这在基础架构层(决定什么代表正确，以及exactly-once的范围是什么)和实现层都很有挑战性。 

流处理系统的早期用户愿意接受框架的局限性，并在应用层想办法弥补(例如使应用程序具有幂等性，或者用批量计算层再做一遍计算)。



Flink的一个重大价值在于，它既保证了exactly-once，也具有低延迟和高吞吐的处理能力。

从根本上说，Flink通过使自身满足所有需求来避免权衡，它是业界的一次意义重大的技术飞跃。



 **端到端（end-to-end）状态一致性:**

目前我们看到的一致性保证都是由流处理器实现的，也就是说都是在 Flink 流处理器内部保证的；而在真实应用中，**流处理应用除了流处理器以外还包含了数据源（例如 Kafka）和输出到持久化系统。**

端到端的一致性保证，意味着结果的正确性贯穿了整个流处理应用的始终；每一个组件都保证了它自己的一致性，整个端到端的一致性级别取决于所有组件中一致性最弱的组件。



具体可以划分如下：

- [ ] source端 —— 需要外部源可重设数据的读取位置

- [ ] flink内部 —— 依赖checkpoint

- [ ] sink端 —— 需要保证从故障恢复时，数据不会重复写入外部系统

而对于sink端，又有两种具体的实现方式：幂等（Idempotent）写入和事务性（Transactional）写入。



- 幂等写入

所谓幂等操作，是说一个操作，可以重复执行很多次，但只导致一次结果更改，也就是说，后面再重复执行就不起作用了。

- 事务写入

需要构建事务来写入外部系统，构建的事务对应着 checkpoint，等到 checkpoint 真正完成的时候，才把所有对应的结果写入 sink 系统中。对于事务性写入，具体又有两种实现方式：预写日志（WAL）和两阶段提交（2PC）。

![1569211221708](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211221708.png)

DataStream API 提供了GenericWriteAheadSink模板类和TwoPhaseCommitSinkFunction 接口，可以方便地实现这两种方式的事务性写入。

不同 Source 和 Sink 的一致性保证可以用下表说明：

| sink/source     | 不可重置     | 可重置                                 |
| --------------- | ------------ | -------------------------------------- |
| 任意(Any)       | At-most-once | At-least-once                          |
| 幂等            | At-most-once | Exactly-once(故障恢复会出现暂时不一致) |
| 预写日志(WAL)   | At-most-once | At-most-once                           |
| 两阶段提交(2PC) | At-most-once | Exactly-once                           |



### 容错机制(checkpoint)

**Flink具体如何保证exactly-once呢? 它使用一种被称为"检查点"（checkpoint）的特性，在出现故障时将系统重置回正确状态。**



Flink检查点算法的正式名称是**异步分界线快照**(asynchronous barrier snapshotting)。该算法大致基于Chandy-Lamport分布式快照算法。检查点是Flink最有价值的创新之一，因为它使Flink可以保证exactly-once，并且不需要牺牲性能。



##### 一致性检查点

![1569211223996](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211223996.png)

- Flink 故障恢复机制的核心，就是应用状态的一致性检查点

- 有状态流应用的一致检查点，其实就是**所有任务的状态**，在某个时间点的一份拷贝（一份快照）；**这个时间点，应该是所有任务都恰好处理完一个相同的输入数据的时候**

- 在JobManager中也有个Chechpoint的指针，指向了仓库的状态快照的一个拓扑图，为以后的数据故障恢复做准备



##### 从检查点恢复状态

![1569211243141](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211243141.png)

- 在执行流应用程序期间，Flink 会定期保存状态的一致检查点

- 如果发生故障， Flink 将会使用最近的检查点来一致恢复应用程序的状态，并重新启动处理流程

  （**如图中所示，7这个数据被source读到了，准备传给奇数流时，奇数流宕机了，数据传输发生中断**）

  ![1569211201608](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211201608.png)

- 遇到故障之后，第一步就是重启应用

  (**重启后，起初流都是空的**)

  ![1569211245435](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211245435.png)

- 第二步是从 checkpoint 中读取状态，将状态重置

  *(\**读取在远程仓库**(Storage，这里的仓库指状态后端保存数据指定的三种方式之一)**保存的状态**)*

- 从检查点重新启动应用程序后，其内部状态与检查点完成时的状态完全相同

  ![1569211221055](C:\Users\87603\AppData\Roaming\Typora\typora-user-images\1569211221055.png)

- 第三步：开始消费并处理检查点到发生故障之间的所有数据

- **这种检查点的保存和恢复机制可以为应用程序状态提供“精确一次”（exactly-once）的一致性，因为所有算子都会保存检查点并恢复其所有状态，这样一来所有的输入流就都会被重置到检查点完成时的位置**



##### 保存点

**CheckPoint为自动保存，SavePoint为手动保存**

- Flink还提供了可以自定义的镜像保存功能，就是保存点（save points）
- 原则上，创建保存点使用的算法与检查点完全相同，因此保存点可以认为就是具有一些额外元数据的检查点
- Flink不会自动创建保存点，因此用户（或者外部调度程序）必须明确地触发创建操作
- 保存点是一个强大的功能。除了故障恢复外，保存点可以用于：有计划的手动备份、更新应用程序、版本迁移、暂停和重启程序，等等



##### 检查点和重启策略配置

java代码 

```
package apitest.state;

import apitest.beans.SensorReading;
import org.apache.flink.api.common.restartstrategy.RestartStrategies;
import org.apache.flink.api.common.time.Time;
import org.apache.flink.contrib.streaming.state.RocksDBStateBackend;
import org.apache.flink.runtime.state.filesystem.FsStateBackend;
import org.apache.flink.runtime.state.memory.MemoryStateBackend;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

/**
 * @author : Ashiamd email: ashiamd@foxmail.com
 * @date : 2021/2/2 11:35 PM
 */
public class StateTest4_FaultTolerance {
  public static void main(String[] args) throws Exception {
    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
    env.setParallelism(1);

    // 1. 状态后端配置
    env.setStateBackend(new MemoryStateBackend());
    env.setStateBackend(new FsStateBackend(""));
    // 这个需要另外导入依赖
    env.setStateBackend(new RocksDBStateBackend(""));

    // 2. 检查点配置 (每300ms让jobManager进行一次checkpoint检查)
    env.enableCheckpointing(300);

    // 高级选项
    env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
    //Checkpoint的处理超时时间
    env.getCheckpointConfig().setCheckpointTimeout(60000L);
    // 最大允许同时处理几个Checkpoint(比如上一个处理到一半，这里又收到一个待处理的Checkpoint事件)
    env.getCheckpointConfig().setMaxConcurrentCheckpoints(2);
    // 与上面setMaxConcurrentCheckpoints(2) 冲突，这个时间间隔是 当前checkpoint的处理完成时间与接收最新一个checkpoint之间的时间间隔
    env.getCheckpointConfig().setMinPauseBetweenCheckpoints(100L);
    // 如果同时开启了savepoint且有更新的备份，是否倾向于使用更老的自动备份checkpoint来恢复，默认false
    env.getCheckpointConfig().setPreferCheckpointForRecovery(true);
    // 最多能容忍几次checkpoint处理失败（默认0，即checkpoint处理失败，就当作程序执行异常）
    env.getCheckpointConfig().setTolerableCheckpointFailureNumber(0);

    // 3. 重启策略配置
    // 固定延迟重启(最多尝试3次，每次间隔10s)
    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(3, 10000L));
    // 失败率重启(在10分钟内最多尝试3次，每次至少间隔1分钟)
    env.setRestartStrategy(RestartStrategies.failureRateRestart(3, Time.minutes(10), Time.minutes(1)));

    // socket文本流
    DataStream<String> inputStream = env.socketTextStream("localhost", 7777);

    // 转换成SensorReading类型
    DataStream<SensorReading> dataStream = inputStream.map(line -> {
      String[] fields = line.split(",");
      return new SensorReading(fields[0], new Long(fields[1]), new Double(fields[2]));
    });

    dataStream.print();
    env.execute();
  }
}
```



##### 状态一致性

- 有状态的流处理，内部每个算子任务都可以有自己的状态
- 对于流处理器内部来说，所谓的状态一致性，其实就是我们所说的计算结果要保证准确。
- 一条数据不应该丢失，也不应该重复计算
- 在遇到故障时可以恢复状态，恢复以后的重新计算，结果应该也是完全正确的。





### Flink+Kafka端到端一致性保证



- 内部——利用checkpoint机制，把状态存盘，发生故障的时候可以恢复，保证内部的状态一致性
- source——kafka consumer作为source，可以将偏移量保存下来，如果后续任务出现了故障，恢复的时候可以由连接器重制偏移量，重新消费数据，保证一致性
- sink——kafka producer作为sink，采用两阶段提交sink，需要实现一个TwoPhaseCommitSinkFunction



##### Exactly-once 两阶段提交

- JobManager 协调各个 TaskManager 进行 checkpoint 存储
- checkpoint保存在 StateBackend中，默认StateBackend是内存级的，也可以改为文件级的进行持久化保存
- 当所有算子任务的快照完成，也就是这次的 checkpoint 完成时，JobManager 会向所有任务发通知，确认这次 checkpoint 完成
- sink 任务收到确认通知，正式提交之前的事务，kafka 中未确认数据改为“已确认”

##### Exactly-once 两阶段提交步骤总结

1. 第一条数据来了之后，开启一个 kafka 的事务（transaction），正常写入 kafka 分区日志但标记为未提交，这就是“预提交”
2. jobmanager 触发 checkpoint 操作，barrier 从 source 开始向下传递，遇到 barrier 的算子将状态存入状态后端，并通知 jobmanager
3. sink 连接器收到 barrier，保存当前状态，存入 checkpoint，通知 jobmanager，并开启下一阶段的事务，用于提交下个检查点的数据
4. jobmanager 收到所有任务的通知，发出确认信息，表示 checkpoint 完成
5. sink 任务收到 jobmanager 的确认信息，正式提交这段时间的数据
6. 外部kafka关闭事务，提交的数据可以正常消费了。