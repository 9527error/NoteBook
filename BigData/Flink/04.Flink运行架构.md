### Flink运行架构



Flink Runtime 层的主要架构如下图所示，它展示了一个 Flink 集群的基本结构。整体来说，它采用了标准 master-slave 的结构，master负责管理整个集群中的资源和作业；TaskManager 则是 Slave，负责提供具体的资源并实际执行作业

![img](file:///C:\Users\87603\AppData\Local\Temp\ksohtml9268\wps1.jpg)



#### 核心组件

- **作业管理器(Jobmanage)**

  负责管理作业的执行，在一个 Flink 集群中可能有多个作业同时执行，每个作业	都有自己的 JobManager 组件

- **资源管理器(ResourceManager)**

  负责资源的管理，在整个 Flink 集群中只有一个 ResourceManager

- **任务管理器（TaskManager）**

  主要负责执行具体的task任务，从JobManager处接收需要部署的 Task，部署启动后，与自己的上游建立连接，接收数据并处理。

- **分发器（Dispatcher）**

  负责接收用户提供的作业，并且负责为这个新提交的作业启动一个新的 JobManager 组件



##### 作业管理器(Jobmanage)

控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的JobManager所控制执行。

​    JobManager会先接收到要执行的应用程序，这个应用程序会包括：

- 作业图（JobGraph）
- 逻辑数据流图（logical dataflow graph）
- 打包了所有的类、库和其它资源的JAR包。

​    JobManager会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。

​    **JobManager会向资源管理器（ResourceManager）请求执行任务必要的资源，也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上**。

​    在运行过程中，JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。



##### 资源管理器(ResourceManage)

​      主要负责管理任务管理器（TaskManager）的插槽（slot）,TaskManger插槽是Flink中定义的处理资源单元。

​    Flink为不同的环境和资源管理工具提供了不同资源管理器，比如YARN、Mesos、K8s，以及standalone部署。

​    **当JobManager申请插槽资源时，ResourceManager会将有空闲插槽的TaskManager分配给JobManager**。如果ResourceManager没有足够的插槽来满足JobManager的请求，它还可以向资源提供平台发起会话，以提供启动TaskManager进程的容器。

​    另外，**ResourceManager还负责终止空闲的TaskManager，释放计算资源**。



##### 任务管理器(TaskManage)

​    Flink中的工作进程。通常在Flink中会有多个TaskManager运行，每一个TaskManager都包含了一定数量的插槽（slots）。**插槽的数量限制了TaskManager能够执行的任务数量**。

​    启动之后，TaskManager会向资源管理器注册它的插槽；收到资源管理器的指令后，TaskManager就会将一个或者多个插槽提供给JobManager调用。JobManager就可以向插槽分配任务（tasks）来执行了。

​    **在执行过程中，一个TaskManager可以跟其它运行同一应用程序的TaskManager交换数据**。



##### 分发器(Dispatcher)

​    可以跨作业运行，它为应用提交提供了REST接口。

​     当一个应用被提交执行时，分发器就会启动并将应用移交给一个JobManager。由于是REST接口，所以Dispatcher可以作为集群的一个HTTP接入点，这样就能够不受防火墙阻挡。Dispatcher也会启动一个Web  UI，用来方便地展示和监控作业执行的信息。

​    Dispatcher在架构中可能并不是必需的，这取决于应用提交运行的方式。





#### 任务调度原理



##### TaskManage和Solt

![img](file:///C:\Users\87603\AppData\Local\Temp\ksohtml9268\wps2.jpg)



- Flink中每一个worker(TaskManager)都是一个JVM进程，它可能会在独立的线程上执行一个Task。
- 为了控制一个worker能接收多少个task，worker通过Task Slot来进行控制（一个worker至少有一个Task Slot）。
- 可以将Flink的solt类比为Spark 的core
- Spark的core空闲的时候不能共享给其他Job使用，Flink可以内部共享使用，将solt共享给其他Job
- 不会涉及到CPU的隔离，solt目前仅仅用来隔离task 的受管理的内存



##### Parallelism(并行度)

- Spark的并行度设置后需要调用特殊的算子（repartition）或特殊的操作（shuffle）才能进行改变，比如调用flatMap算子后再调用repartition改变分区。

- Flink的并行度设置可以在任何算子后使用，并且为了方便，也可以设置全局并行度

- 并行度优先级：算子>env>提交参数>配置文件

- 如果Flink的一个算子的并行度为2，那么这个算子在执行时，这个算子对应的task就会拆分成2个subtask，发到不同的Slot中执行

  ![img](file:///C:\Users\87603\AppData\Local\Temp\ksohtml9268\wps3.jpg)


##### 

- 一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）
- 一般情况下，一个流程序的并行度，可以认为就是其所有算子中最大的并行度。一个程序中，不同的算子可能具有不同的并行度。
- 算子传输数据模式
  - **One-to-one**: stream(比如在source和map operator之间)维护着分区以及元素的顺序。那意味着flatmap 算子的子任务看到的元素的个数以及顺序跟source 算子的子任务生产的元素的个数、顺序相同，map、fliter、flatMap等算子都是one-to-one的对应关系。**类似于spark中的窄依赖**
  - **Redistributing**:stream(map()跟keyBy/window之间或者keyBy/window跟sink之间)的分区会发生改变。每一个算子的子任务依据所选择的transformation发送数据到不同的目标任务。例如，keyBy()基于hashCode重分区(类似于shuffle)、broadcast和rebalance会随机重新分区，这些算子都会引起redistribute过程，而redistribute过程就类似于Spark中的shuffle过程。**类似于spark中的宽依赖**



##### 程序和数据流(DataFlow)

- **所有的Flink程序都是由三部分组成的： Source 、Transformation 和 Sink。**
- Source 负责读取数据源，Transformation 利用各种算子进行处理加工，Sink 负责输出
- 在运行时，Flink上运行的程序会被映射成“逻辑数据流”（dataflows），它包含了这三部分
- 每一个dataflow以一个或多个sources开始以一个或多个sinks结束。dataflow类似于任意的有向无环图（DAG）
- 在大部分情况下，程序中的转换运算（transformations）跟dataflow中的算子（operator）是一一对应的关系



##### Task与SubTask

Flink执行时,由于并行度的设置，**可以将同一个Job不同算子的subtask放在同一块内存中进行处理**，那么这样在执行时就可以合并成一个完整的task进行处理，而不是独立的子任务，这样就减少了子任务（SubTask）之间调度和数据传递的性能损耗



##### Operator Chains(任务链)

在Flink执行计算时，多个算子的subTask到底能不能组成一个Task是不确定的。比如读取并行度为1的数据源，但是map映射时使用并行度2，那么这样map算子就存在两个subtask，可以数据源读取时只有一个subtask，那么就会导致其中一个subtask无法链接成task，就需要在其他slot中执行。所以在这种情况下，到底哪些subtask可以组合，哪些subtask不能组合，就需要动态调整，这就需要用到一种任务链的操作进行设置。

![img](file:///C:\Users\87603\AppData\Local\Temp\ksohtml9268\wps4.jpg)



任务链必须满足的条件：

- One-to-One 的数据传输
- 并行度相同



##### ExecutionGraph(执行图)

- Flink 中的执行图可以分成四层：StreamGraph -> JobGraph -> ExecutionGraph -> 物理执行图。
  - **StreamGraph**：是根据用户通过Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构。
  - **JobGraph**：StreamGraph经过优化后生成了JobGraph，提交给JobManager 的数据结构。主要的优化为，将多个符合条件的节点chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。
  - **ExecutionGraph**：JobManager 根据JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。
  - **物理执行图**：JobManager 根据ExecutionGraph 对Job 进行调度后，在各个TaskManager 上部署Task 后形成的“图”，并不是一个具体的数据结构。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200524220232635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgwMjI5,size_16,color_FFFFFF,t_70)



#### 提交流程

![img](file:///C:\Users\87603\AppData\Local\Temp\ksohtml9268\wps5.jpg)



1.  Flink任务提交后，Client向HDFS上传Flink的Jar包和配置
2.  向Yarn ResourceManager提交任务，ResourceManager分配Container资源
3.  通知对应的NodeManager启动ApplicationMaster，ApplicationMaster启动后加载Flink的Jar包和配置构建环境，然后启动JobManager
4. ApplicationMaster向ResourceManager申请资源启动TaskManager
5. ResourceManager分配Container资源后，由ApplicationMaster通知资源所在节点的NodeManager启动TaskManager
6. NodeManager加载Flink的Jar包和配置构建环境并启动TaskManager
7.  TaskManager启动后向JobManager发送心跳包，并等待JobManager向其分配任务。



